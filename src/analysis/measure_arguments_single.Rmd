---
title: "Gas Cost Estimator: estimation of impact of arguments on gas costs"
output: html_document
params:
  env: "besu"
  programs: "pg_arguments_short_short.csv"
  results: "results_arguments_short_besu.csv"
  marginal_estimated_cost: "reports-08.11.2024/estimated_cost_besu_full.csv"
  output_estimated_cost: ""
  details: ""
---

```{r, setup, include=FALSE}
library(sqldf)
library(nlme)
library(mixtools)
library(zeallot) # for multi-assignment %<-%

knitr::opts_knit$set(root.dir = '/home/lukaszglen/sources/imapp5/local')

if (params$env == "") {
  stop("'env' param is missing, the name of EVM client")
}
env = params$env

if (params$programs == "") {
  stop("'programs' param is missing, the file with test programs")
}

if (params$results == "") {
  stop("'results' param is missing, the file with measurements results")
}

if (params$details == "") {
  details = TRUE
} else {
  details = tolower(params$details) %in% c("1", "t", "true", "on")
}

removed_outliers = TRUE
marginal_estimated_cost_empty = params$marginal_estimated_cost == ""
```


In this script we conduct the estimation for the `measure_arguments` approach.

EVM client ENV=`r params$env`. 

The file with programs PROGRAMS=`r params$programs`. 

The file with measurement results RESULTS=`r params$results`. 

The optional comma separated list of estimated costs obtained in the marginal procedure MARGINAL_ESTIMATED_COST-`r params$marginal_estimated_cost`.

The optional file to output estimated costs and results OUTPUT_ESTIMATED_COST-`r params$marginal_estimated_cost`.

```{r, include=FALSE}
load_data_set_from_file <- function(filepath) {
  result = read.csv(filepath)
  result$env = env
  if (!('measure_total_time_ns' %in% colnames(result))) {
    if ('total_time_ns' %in% colnames(result)) {
      result$measure_total_time_ns = result$total_time_ns
    }
  }
  if (!('measure_total_timer_time_ns' %in% colnames(result))) {
    if ('engine_overhead_time_ns' %in% colnames(result)) {
      result$measure_total_timer_time_ns = result$engine_overhead_time_ns
    }
  }
  return(result)
}

programs = read.csv(params$programs)
results = load_data_set_from_file(params$results)
if(!("run_id" %in% colnames(results))) {
  results$run_id <- 1
}

if (!('measure_total_time_ns' %in% colnames(results))) {
  if ('total_time_ns' %in% colnames(results)) {
    results$measure_total_time_ns = results$total_time_ns
  }
}
if (!('measure_total_timer_time_ns' %in% colnames(results))) {
  if ('engine_overhead_time_ns' %in% colnames(results)) {
    results$measure_total_timer_time_ns = results$engine_overhead_time_ns
  }
}

programs$arity <- rowSums(data.frame(!is.na(programs$arg0), !is.na(programs$arg1), !is.na(programs$arg2)))
```

```{r, include=FALSE }
measurements = sqldf("SELECT opcode, op_count, arg0, arg1, arg2, sample_id, run_id, measure_total_time_ns, results.program_id
                     FROM results
                     INNER JOIN
                       programs ON(results.program_id = programs.program_id)
                     ")
measurements$env <- env
# measurements$opcode = factor(measurements$opcode, levels=unique(programs$opcode))
```

```{r, include=FALSE}
marginal_estimated_cost = data.frame(op=character(0),estimate_marginal_ns=numeric(0),estimate_marginal_ns_stderr=numeric(0),env=character(0))

if(!marginal_estimated_cost_empty){
  all_estimated_cost_files = strsplit(params$marginal_estimated_cost, split="\\s*,\\s*")[[1]]
  for (i in 1:length(all_estimated_cost_files)) {
    add_estimated_cost = read.csv(all_estimated_cost_files[i])
    marginal_estimated_cost = rbind(marginal_estimated_cost, add_estimated_cost[, c("op", "estimate_marginal_ns", "estimate_marginal_ns_stderr", "env")])
  }
  if (nrow(marginal_estimated_cost) == 0) {
    stop("No marginal estimated cost data found.")
  }
  if (nrow(marginal_estimated_cost[which(marginal_estimated_cost$env != env), ]) > 0) {
    stop("Invalid EVM in marginal estimated cost files.")
  }
}
```

```{r, include=FALSE}
remove_outliers <- function(df, col) { # TODO per op_count?
  boxplot_result = boxplot(df[, col] ~ df[, 'op_count'] + df[, 'opcode'], plot=FALSE)
  outliers = boxplot_result$out
  if (length(outliers) == 0) {
    no_outliers <- df
  } else {
    names = boxplot_result$names[boxplot_result$group]
    all_row_identifiers = paste(df[, col], df[, 'op_count'], df[, 'opcode'], sep='.')
    outlier_row_identifiers = paste(outliers, names, sep='.')
    no_outliers = df[-which(all_row_identifiers %in% outlier_row_identifiers), ]
  }
  return(no_outliers)
}
```

```{r fig.width=15, fig.height=10}
if ( !removed_outliers) {
  boxplot(measure_total_time_ns ~ opcode, data=measurements, las=2, outline=TRUE, log='y', main=paste(env, 'all'))
}
```

```{r fig.width=15, fig.height=18}
if (removed_outliers) {
  par(mfrow=c(2, 1))
  
  # before
  boxplot(measure_total_time_ns ~ opcode, data=measurements, las=2, outline=TRUE, log='y', main=paste(env, 'all'))

  measurements = remove_outliers(measurements, 'measure_total_time_ns')
  
  # after
  boxplot(measure_total_time_ns ~ opcode, data=measurements, las=2, outline=TRUE, log='y', main=paste(env, 'no_outliers'))
}
```

TODO remove_outliers_2 ?

# Detailed view

This is massive and detailed overview on the impact of arguments. 
Because of the number of charts, only `op count = 30` is eligible. Feel free to change it, but that should not be anyhow more informative.
The visualizations do not guarantee that all dependencies are clearly seen. 
Especially for binary and ternary opcodes where impacts of arg0, arg1 and arg2 are mixed.
But if a dependency is graphically noticeable that you should expect also statistical dependency.

```{r, include=FALSE}
opcode_arity_df <- aggregate(arity ~ opcode, programs, max)

# just check is all programs for a given opcode are the same
opcode_arity_compare <- merge(x = programs[, c("opcode", "arity")], y = opcode_arity_df, by = "opcode")
if (nrow(opcode_arity_compare[which(opcode_arity_compare$arity.x != opcode_arity_compare$arity.y), ]) > 0) {
  stop("programs arity is inconsistent")
}
```

```{r fig.width=15}
for(i in 1:nrow(opcode_arity_df)) {
  opcode_arity <- opcode_arity_df[i,]
  opcode <- opcode_arity[["opcode"]]
  arity <- opcode_arity[["arity"]]
  if (arity >= 1) {
    plot(measure_total_time_ns ~ arg0, data=measurements[which(measurements$opcode == opcode & measurements$op_count == 30), ], pch=5, col='blue')
    title(main = paste(env, opcode, 'arg0', 'opcount 30'))
  }
  if (arity >= 2) {
    plot(measure_total_time_ns ~ arg1, data=measurements[which(measurements$opcode == opcode & measurements$op_count == 30), ], pch=5, col='blue')
    title(main = paste(env, opcode, 'arg1', 'opcount 30'))
  }
  if (arity >= 3) {
    plot(measure_total_time_ns ~ arg2, data=measurements[which(measurements$opcode == opcode & measurements$op_count == 30), ], pch=5, col='blue')
    title(main = paste(env, opcode, 'arg2', 'opcount 30'))
  }
}
```

# Models

Notes:
1. Outliers need to be removed if detected
2. The `argX:op_count` interactions measure the impact on the OPCODE
3. The `argX` are just auxiliary variables added to exclude the effect of cheaper/more expensive PUSHes. We only want to extract the effect of the argument on the measured OPCODE repeated `op_count` times.

This is the so-called "first-pass" at the estimation procedure, where we estimated all possible argument impact variables
for all OPCODEs.
We gather all the results in the `first_pass` table, inspect this to see where the arguments turned out to be significantly impacting the computation cost.

```{r, include=FALSE}
# Every `arg` coefficient represents the impact of the argument's byte size growing by 1.
# We treat as impactful the arguments where p-value is effectively zero. The previous approach was:
# Treat as impactful the arguments, where:
# 1. The estimate is significant with confidence 0.001
# 2. The increase of arg's byte size by 1 will increase the cost by more than 1%
# but it turned out to be much less stable in practice.
# p_value_thresh = 1e-30
p_value_thresh = 0.001
# impact_ratio = 0.00
impact_ratio = 0.01

ifNA <- function(x, v) {
  ifelse(is.na(x), v, x)
}

first_pass = data.frame(opcode=character(0),estimate_marginal_ns=numeric(0),
                        arg0_ns_raw=numeric(0), arg1_ns_raw=numeric(0), arg2_ns_raw=numeric(0),
                        arg0_ns_p=numeric(0), arg1_ns_p=numeric(0), arg2_ns_p=numeric(0))

for(i in 1:nrow(opcode_arity_df)) {
  opcode_arity <- opcode_arity_df[i,]
  opcode <- opcode_arity[["opcode"]]
  arity <- opcode_arity[["arity"]]
  args_ns_raw = c(NA, NA, NA)
  args_ns_p = c(NA, NA, NA)
  if (arity == 1) {
    model = lm(measure_total_time_ns ~ op_count + arg0 + arg0:op_count, data=measurements[which(measurements$opcode==opcode), ])
  }
  if (arity == 2) {
    model = lm(measure_total_time_ns ~ op_count + arg0 + arg1 + arg0:op_count + arg1:op_count, data=measurements[which(measurements$opcode==opcode), ])
  }
  if (arity == 3) {
    model = lm(measure_total_time_ns ~ op_count + arg0 + arg1 + arg2 + arg0:op_count + arg1:op_count + arg2:op_count, data=measurements[which(measurements$opcode==opcode), ])
  }
  all_coefficients = summary(model)$coefficients
  arg_coefficients = all_coefficients[!(row.names(all_coefficients) %in% c("op_count", "(Intercept)", "arg0", "arg1", "arg2")), , drop = FALSE]
  pure_op_count_coeff = all_coefficients["op_count", 1]
  
  # it may be that lm drops a coefficient if its arguments are constant,
  # this is a way to exclude an arg from examination
  arg_coefficients_names = row.names(arg_coefficients)
  if ("op_count:arg0" %in% arg_coefficients_names) {
    args_ns_raw[1] = arg_coefficients["op_count:arg0", 1]
    args_ns_p[1] = arg_coefficients["op_count:arg0", 4]
  }
  if ("op_count:arg1" %in% arg_coefficients_names) {
    args_ns_raw[2] = arg_coefficients["op_count:arg1", 1]
    args_ns_p[2] = arg_coefficients["op_count:arg1", 4]
  }
  if ("op_count:arg2" %in% arg_coefficients_names) {
    args_ns_raw[3] = arg_coefficients["op_count:arg2", 1]
    args_ns_p[3] = arg_coefficients["op_count:arg2", 4]
  }
  
  first_pass[nrow(first_pass) + 1, ] = list(opcode, pure_op_count_coeff, args_ns_raw[1], args_ns_raw[2], args_ns_raw[3], args_ns_p[1], args_ns_p[2], args_ns_p[3])
}

first_pass$has_impacting_arg0 <- !is.na(first_pass$arg0_ns_raw) & !is.na(first_pass$arg0_ns_p) & first_pass$arg0_ns_p < p_value_thresh & abs(ifNA(first_pass$arg0_ns_raw, 0)) > first_pass$estimate_marginal_ns * impact_ratio
first_pass$has_impacting_arg1 <- !is.na(first_pass$arg1_ns_raw) & !is.na(first_pass$arg1_ns_p) & first_pass$arg1_ns_p < p_value_thresh & abs(ifNA(first_pass$arg1_ns_raw, 0)) > first_pass$estimate_marginal_ns * impact_ratio
first_pass$has_impacting_arg2 <- !is.na(first_pass$arg2_ns_raw) & !is.na(first_pass$arg2_ns_p) & first_pass$arg2_ns_p < p_value_thresh & abs(ifNA(first_pass$arg2_ns_raw, 0)) > first_pass$estimate_marginal_ns * impact_ratio

first_pass$has_impacting <- first_pass$has_impacting_arg0 | first_pass$has_impacting_arg1 | first_pass$has_impacting_arg2
```

```{r, include=FALSE}
args_estimates = data.frame(opcode=character(0),arg=character(0),ns_raw=numeric(0),ns_p=numeric(0),has_impacting=logical(0))
for(i in 1:nrow(first_pass)) {
  opcode_estimates <- first_pass[i,]
  if (!is.na(opcode_estimates[["arg0_ns_raw"]])) {
    args_estimates[nrow(args_estimates) + 1, ] = list(opcode_estimates[["opcode"]], "0", opcode_estimates[["arg0_ns_raw"]], opcode_estimates[["arg0_ns_p"]], opcode_estimates[["has_impacting_arg0"]])
  }
  if (!is.na(opcode_estimates[["arg1_ns_raw"]])) {
    args_estimates[nrow(args_estimates) + 1, ] = list(opcode_estimates[["opcode"]], "1", opcode_estimates[["arg1_ns_raw"]], opcode_estimates[["arg1_ns_p"]], opcode_estimates[["has_impacting_arg1"]])
  }
  if (!is.na(opcode_estimates[["arg2_ns_raw"]])) {
    args_estimates[nrow(args_estimates) + 1, ] = list(opcode_estimates[["opcode"]], "2", opcode_estimates[["arg2_ns_raw"]], opcode_estimates[["arg2_ns_p"]], opcode_estimates[["has_impacting_arg2"]])
  }
}
```

```{r}
if (details) {
  args_estimates
} else {
  args_estimates[which(args_estimates$has_impacting), ]
}
```

```{r, include=FALSE}
# it may be that for opcode with arity == 3 or arity == 2 only 1 arg is examined, use_arg is the arg
plot_args_dependency_1 <- function(df, opcode, use_arg) {
  arg_name = paste0('arg', use_arg)
  aggregate_formula = as.formula(paste0('measure_total_time_ns ~ op_count * ', arg_name))
  df <- aggregate(aggregate_formula, df[which(df$opcode==opcode), ], mean)

  plot_data = df[which(df$op_count == max(df$op_count)), ]

  plot_formula = as.formula(paste0('measure_total_time_ns ~ ', arg_name))
  plot(plot_formula, data=plot_data, pch=19, xlab=arg_name, ylab="measure_total_time_ns")
  title(main=paste(opcode, paste0(c("measure_total_time_ns", arg_name), collapse="~")))
}

# it may be that for opcode with arity == 3 only 2 args are examined, use_args is a list of these two args
plot_args_dependency_2 <- function(df, opcode, use_args) {
  args_names = paste0('arg', use_args)
  args_formula_str = paste0(args_names, collapse=' * ')
  aggregate_formula = as.formula(paste0('measure_total_time_ns ~ op_count * ', args_formula_str))
  df <- aggregate(aggregate_formula, df[which(df$opcode==opcode), ], mean)

  plot_data = df[which(df$op_count == max(df$op_count)), ]
  decreasing_colors = heat.colors(nrow(plot_data))
  plot_data=plot_data[order(plot_data$measure_total_time_ns, decreasing=TRUE), ]
  
  plot(plot_data[, args_names[1]], plot_data[, args_names[2]], col=decreasing_colors, pch=19, xlab=args_names[1], ylab=args_names[2])
  title(main=paste(opcode, paste0(rev(paste0('arg', use_args)), collapse="~")))
}

if (details) {
  proceed_with_opcodes <- first_pass[, "opcode"]
} else {
  proceed_with_opcodes <- first_pass[which(first_pass$has_impacting), "opcode"]
}
```

```{r fig.width=15}
for(opcode in proceed_with_opcodes) {
  working_args <- args_estimates[which(args_estimates$opcode == opcode), "arg"]
  if (length(working_args) == 1) {
    plot_args_dependency_1(measurements, opcode, working_args[[1]])
  } else if (length(working_args) == 2) {
    plot_args_dependency_2(measurements, opcode, working_args)
  }
}
```

# Verification against marginal estimations

In this section we compare opcodes cost obtained in the arguments course with previous estimations obtained in the marginal procedure.

`r if(marginal_estimated_cost_empty){"No marginal estimated cost files given."}`

```{r, include = FALSE}
q <- "SELECT first_pass.opcode, first_pass.estimate_marginal_ns AS 'estimate_marginal_ns inner', marginal_estimated_cost.estimate_marginal_ns AS 'estimate_marginal_ns outer' FROM first_pass LEFT JOIN marginal_estimated_cost ON first_pass.opcode = marginal_estimated_cost.op"
compare_marginal <- sqldf(q)
compare_marginal$'rel diff' <- (compare_marginal$'estimate_marginal_ns inner' / compare_marginal$'estimate_marginal_ns outer') - 1
```

```{r, include = !marginal_estimated_cost_empty}
compare_marginal
```

```{r, incude = FALSE}
if (params$output_estimated_cost != "") {
  write.csv(first_pass, params$output_estimated_cost, quote=FALSE, row.names=FALSE)
}
```

