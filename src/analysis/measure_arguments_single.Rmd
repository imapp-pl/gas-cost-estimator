---
title: "Gas Cost Estimator: estimation of impact of arguments on gas costs"
output: html_document
params:
  env: "besu"
  programs: "pg_arguments_short.csv"
  results: "results_arguments_short_besu.csv"
  marginal_estimated_cost: "reports-08.11.2024/estimated_cost_besu_full.csv"
  output_estimated_cost: ""
  details: ""
---

```{r, setup, include=FALSE}
library(sqldf)
library(nlme)
library(mixtools)
library(zeallot) # for multi-assignment %<-%

knitr::opts_knit$set(root.dir = '/home/lukaszglen/sources/imapp5/local')

if (params$env == "") {
  stop("'env' param is missing, the name of EVM client")
}
env = params$env

if (params$programs == "") {
  stop("'programs' param is missing, the file with test programs")
}

if (params$results == "") {
  stop("'results' param is missing, the file with measurements results")
}

if (params$details == "") {
  details = TRUE
} else {
  details = tolower(params$details) %in% c("1", "t", "true", "on")
}

removed_outliers = TRUE
marginal_estimated_cost_empty = params$marginal_estimated_cost == ""
```


In this script we conduct the estimation for the `measure_arguments` approach. 
It is to verify and detect arguments cost for opcodes execution.

Below are the parameters used for this report.

EVM client ENV=`r params$env`. 

The file with programs PROGRAMS=`r params$programs`. 

The file with measurement results RESULTS=`r params$results`. 

The optional comma separated list of estimated costs obtained in the marginal procedure MARGINAL_ESTIMATED_COST-`r params$marginal_estimated_cost`.

The optional file to output estimated costs and results OUTPUT_ESTIMATED_COST-`r params$marginal_estimated_cost`.

```{r, include=FALSE}
load_data_set_from_file <- function(filepath) {
  result = read.csv(filepath)
  result$env = env
  if (!('measure_total_time_ns' %in% colnames(result))) {
    if ('total_time_ns' %in% colnames(result)) {
      result$measure_total_time_ns = result$total_time_ns
    }
  }
  if (!('measure_total_timer_time_ns' %in% colnames(result))) {
    if ('engine_overhead_time_ns' %in% colnames(result)) {
      result$measure_total_timer_time_ns = result$engine_overhead_time_ns
    }
  }
  return(result)
}

programs = read.csv(params$programs)
results = load_data_set_from_file(params$results)
if(!("run_id" %in% colnames(results))) {
  results$run_id <- 1
}

if (!('measure_total_time_ns' %in% colnames(results))) {
  if ('total_time_ns' %in% colnames(results)) {
    results$measure_total_time_ns = results$total_time_ns
  }
}
if (!('measure_total_timer_time_ns' %in% colnames(results))) {
  if ('engine_overhead_time_ns' %in% colnames(results)) {
    results$measure_total_timer_time_ns = results$engine_overhead_time_ns
  }
}

programs$arity <- rowSums(data.frame(!is.na(programs$arg0), !is.na(programs$arg1), !is.na(programs$arg2)))
```

```{r, include=FALSE }
measurements = sqldf("SELECT opcode, op_count, arg0, arg1, arg2, sample_id, run_id, measure_total_time_ns, results.program_id
                     FROM results
                     INNER JOIN
                       programs ON(results.program_id = programs.program_id)
                     ")
measurements$env <- env
```

```{r, include=FALSE}
marginal_estimated_cost = data.frame(op=character(0),estimate_marginal_ns=numeric(0),estimate_marginal_ns_stderr=numeric(0),env=character(0))

if(!marginal_estimated_cost_empty){
  all_estimated_cost_files = strsplit(params$marginal_estimated_cost, split="\\s*,\\s*")[[1]]
  for (i in 1:length(all_estimated_cost_files)) {
    add_estimated_cost = read.csv(all_estimated_cost_files[i])
    marginal_estimated_cost = rbind(marginal_estimated_cost, add_estimated_cost[, c("op", "estimate_marginal_ns", "estimate_marginal_ns_stderr", "env")])
  }
  if (nrow(marginal_estimated_cost) == 0) {
    stop("No marginal estimated cost data found.")
  }
  if (nrow(marginal_estimated_cost[which(marginal_estimated_cost$env != env), ]) > 0) {
    stop("Invalid EVM in marginal estimated cost files.")
  }
}
```

```{r, include=FALSE}
remove_outliers <- function(df, col) { # TODO per op_count?
  boxplot_result = boxplot(df[, col] ~ df[, 'op_count'] + df[, 'opcode'], plot=FALSE)
  outliers = boxplot_result$out
  if (length(outliers) == 0) {
    no_outliers <- df
  } else {
    names = boxplot_result$names[boxplot_result$group]
    all_row_identifiers = paste(df[, col], df[, 'op_count'], df[, 'opcode'], sep='.')
    outlier_row_identifiers = paste(outliers, names, sep='.')
    no_outliers = df[-which(all_row_identifiers %in% outlier_row_identifiers), ]
  }
  return(no_outliers)
}
```

```{r fig.width=15, fig.height=10}
if ( !removed_outliers) {
  boxplot(measure_total_time_ns ~ opcode, data=measurements, las=2, outline=TRUE, log='y', main=paste(env, 'all'))
}
```

```{r fig.width=15, fig.height=18}
if (removed_outliers) {
  par(mfrow=c(2, 1))
  
  # before
  boxplot(measure_total_time_ns ~ opcode, data=measurements, las=2, outline=TRUE, log='y', main=paste(env, 'all'))

  measurements = remove_outliers(measurements, 'measure_total_time_ns')
  
  # after
  boxplot(measure_total_time_ns ~ opcode, data=measurements, las=2, outline=TRUE, log='y', main=paste(env, 'no_outliers'))
}
```

# Detailed view

This is massive and detailed overview on the impact of arguments. 
Because of the number of charts, only `op count = 30` is eligible. Feel free to change it, but that should not be anyhow more informative.
The visualizations do not guarantee that all dependencies are clearly seen. 
Especially for binary and ternary opcodes where impacts of arg0, arg1 and arg2 are mixed.
But if a dependency is graphically noticeable that you should expect also statistical dependency.

```{r, include=FALSE}
opcode_arity_df <- aggregate(arity ~ opcode, programs, max)

# just check is all programs for a given opcode are the same
opcode_arity_compare <- merge(x = programs[, c("opcode", "arity")], y = opcode_arity_df, by = "opcode")
if (nrow(opcode_arity_compare[which(opcode_arity_compare$arity.x != opcode_arity_compare$arity.y), ]) > 0) {
  stop("programs arity is inconsistent")
}
```

```{r fig.width=12}
for(i in 1:nrow(opcode_arity_df)) {
  opcode_arity <- opcode_arity_df[i,]
  opcode <- opcode_arity[["opcode"]]
  arity <- opcode_arity[["arity"]]
  if (arity >= 1) {
    plot(measure_total_time_ns ~ arg0, data=measurements[which(measurements$opcode == opcode & measurements$op_count == 30), ], pch=5, col='blue')
    title(main = paste(env, opcode, 'arg0', 'opcount 30'))
  }
  if (arity >= 2) {
    plot(measure_total_time_ns ~ arg1, data=measurements[which(measurements$opcode == opcode & measurements$op_count == 30), ], pch=5, col='blue')
    title(main = paste(env, opcode, 'arg1', 'opcount 30'))
  }
  if (arity >= 3) {
    plot(measure_total_time_ns ~ arg2, data=measurements[which(measurements$opcode == opcode & measurements$op_count == 30), ], pch=5, col='blue')
    title(main = paste(env, opcode, 'arg2', 'opcount 30'))
  }
}
```

# Models


This is the so-called "first-pass" at the estimation procedure, where we estimated all possible argument impact variables
for all OPCODEs.
We gather all the results in the `first_pass` table, inspect this to see where the arguments turned out to be significantly impacting the computation cost.

```{r, include=FALSE}
div_opcodes = c('DIV', 'MOD', 'SDIV', 'SMOD')
expensive_opcodes = c(div_opcodes, 'ADDMOD', 'MULMOD')

# all and only opcodes with expensive (expensive_opcodes) have non NA expensive column
measurements$expensive = NA
measurements[which(measurements$opcode %in% div_opcodes), ]$expensive =
  measurements[which(measurements$opcode %in% div_opcodes), ]$arg0 >
  measurements[which(measurements$opcode %in% div_opcodes), ]$arg1
# remember that argX is the byte-size of the argument in these measurements
measurements[which(measurements$opcode == 'ADDMOD'), ]$expensive =
  8**measurements[which(measurements$opcode == 'ADDMOD'), ]$arg0 +
  8**measurements[which(measurements$opcode == 'ADDMOD'), ]$arg1 > 
  8**measurements[which(measurements$opcode == 'ADDMOD'), ]$arg2
measurements[which(measurements$opcode == 'MULMOD'), ]$expensive =
  measurements[which(measurements$opcode == 'MULMOD'), ]$arg0 +
  measurements[which(measurements$opcode == 'MULMOD'), ]$arg1 >
  measurements[which(measurements$opcode == 'MULMOD'), ]$arg2
```

```{r, include=FALSE}
# Every `arg` coefficient represents the impact of the argument's byte size growing by 1.
# We treat as impactful the arguments where p-value is effectively zero. The previous approach was:
# Treat as impactful the arguments, where:
# 1. The estimate is significant with confidence 0.001
# 2. The increase of arg's byte size by 1 will increase the cost by more than 1%
# but it turned out to be much less stable in practice.
# p_value_thresh = 1e-30
p_value_thresh = 0.001
# impact_ratio = 0.00
impact_ratio = 0.01

ifNA <- function(x, v) {
  ifelse(is.na(x), v, x)
}

first_pass = data.frame(opcode=character(0), 
                        intercept=numeric(0), intercept_p=numeric(0),
                        estimate_marginal_ns=numeric(0), estimate_marginal_ns_p=numeric(0),
                        arg0_ns_raw=numeric(0), arg1_ns_raw=numeric(0), arg2_ns_raw=numeric(0),
                        arg0_ns_p=numeric(0), arg1_ns_p=numeric(0), arg2_ns_p=numeric(0),
                        expensive_ns_raw=numeric(0), expensive_ns_p=numeric(0))

for(i in 1:nrow(opcode_arity_df)) {
  opcode_arity <- opcode_arity_df[i,]
  opcode <- opcode_arity[["opcode"]]
  arity <- opcode_arity[["arity"]]
  if (arity == 0) { 
    if (opcode %in% expensive_opcodes) {
      stop("expensive not supported for null arity")
    } else {
      # TODO is it good?
      model = lm(measure_total_time_ns ~ op_count, data=measurements[which(measurements$opcode==opcode), ])
    }
  }
  if (arity == 1) {
    if (opcode %in% expensive_opcodes) {
      stop("expensive not supported for unary arity")
    } else {
      model = lm(measure_total_time_ns ~ op_count + arg0 + arg0:op_count, data=measurements[which(measurements$opcode==opcode), ])
    }
  }
  if (arity == 2) {
    if (opcode %in% expensive_opcodes) {
      model = lm(measure_total_time_ns ~ op_count + arg0 + arg1 + expensive + arg0:op_count + arg1:op_count + expensive:op_count, data=measurements[which(measurements$opcode==opcode), ])
    } else {
      model = lm(measure_total_time_ns ~ op_count + arg0 + arg1 + arg0:op_count + arg1:op_count, data=measurements[which(measurements$opcode==opcode), ])
    }
  }
  if (arity == 3) {
    if (opcode %in% expensive_opcodes) {
      model = lm(measure_total_time_ns ~ op_count + arg0 + arg1 + arg2 + expensive + arg0:op_count + arg1:op_count + arg2:op_count + expensive:op_count, data=measurements[which(measurements$opcode==opcode), ])
    } else {
      model = lm(measure_total_time_ns ~ op_count + arg0 + arg1 + arg2 + arg0:op_count + arg1:op_count + arg2:op_count, data=measurements[which(measurements$opcode==opcode), ])
    }
  }
  all_coefficients = summary(model)$coefficients
  arg_coefficients = all_coefficients[!(row.names(all_coefficients) %in% c("op_count", "(Intercept)", "arg0", "arg1", "arg2")), , drop = FALSE]
  arg_coefficients_names = row.names(arg_coefficients)

  intercept = all_coefficients["(Intercept)", 1]
  intercept_p = all_coefficients["(Intercept)", 4]
  pure_op_count_coeff = all_coefficients["op_count", 1]
  pure_op_count_coeff_p = all_coefficients["op_count", 4]
  
  args_ns_raw = c(NA, NA, NA)
  args_ns_p = c(NA, NA, NA)
  # it may be that lm drops a coefficient if its arguments are constant,
  # this is a way to exclude an arg from examination
  if ("op_count:arg0" %in% arg_coefficients_names) {
    args_ns_raw[1] = arg_coefficients["op_count:arg0", 1]
    args_ns_p[1] = arg_coefficients["op_count:arg0", 4]
  }
  if ("op_count:arg1" %in% arg_coefficients_names) {
    args_ns_raw[2] = arg_coefficients["op_count:arg1", 1]
    args_ns_p[2] = arg_coefficients["op_count:arg1", 4]
  }
  if ("op_count:arg2" %in% arg_coefficients_names) {
    args_ns_raw[3] = arg_coefficients["op_count:arg2", 1]
    args_ns_p[3] = arg_coefficients["op_count:arg2", 4]
  }
  
  expensive_ns_raw = NA
  expensive_ns_p = NA
  if (opcode %in% expensive_opcodes) {
    expensive_ns_raw = all_coefficients["op_count:expensiveTRUE", 1]
    expensive_ns_p = all_coefficients["op_count:expensiveTRUE", 4]
  }
  
  first_pass[nrow(first_pass) + 1, ] = list(opcode, intercept, intercept_p, pure_op_count_coeff, pure_op_count_coeff_p, args_ns_raw[1], args_ns_raw[2], args_ns_raw[3], args_ns_p[1], args_ns_p[2], args_ns_p[3], expensive_ns_raw, expensive_ns_p)
}

first_pass$has_impacting_arg0 <- !is.na(first_pass$arg0_ns_raw) & !is.na(first_pass$arg0_ns_p) & first_pass$arg0_ns_p < p_value_thresh & abs(ifNA(first_pass$arg0_ns_raw, 0)) > first_pass$estimate_marginal_ns * impact_ratio
first_pass$has_impacting_arg1 <- !is.na(first_pass$arg1_ns_raw) & !is.na(first_pass$arg1_ns_p) & first_pass$arg1_ns_p < p_value_thresh & abs(ifNA(first_pass$arg1_ns_raw, 0)) > first_pass$estimate_marginal_ns * impact_ratio
first_pass$has_impacting_arg2 <- !is.na(first_pass$arg2_ns_raw) & !is.na(first_pass$arg2_ns_p) & first_pass$arg2_ns_p < p_value_thresh & abs(ifNA(first_pass$arg2_ns_raw, 0)) > first_pass$estimate_marginal_ns * impact_ratio

# these arguments are explicitly expressed in the currenct gas cost calculation
first_pass[which(first_pass$opcode == "EXP"), "has_impacting_arg1"] = TRUE
first_pass[which(first_pass$opcode == "KECCAK256"), "has_impacting_arg1"] = TRUE
first_pass[which(first_pass$opcode == "CALLDATACOPY"), "has_impacting_arg2"] = TRUE
first_pass[which(first_pass$opcode == "CODECOPY"), "has_impacting_arg2"] = TRUE
first_pass[which(first_pass$opcode == "EXTCODECOPY"), "has_impacting_arg2"] = TRUE
first_pass[which(first_pass$opcode == "RETURNDATACOPY"), "has_impacting_arg2"] = TRUE
first_pass[which(first_pass$opcode == "MCOPY"), "has_impacting_arg2"] = TRUE
first_pass[which(first_pass$opcode == "LOG0"), "has_impacting_arg1"] = TRUE
first_pass[which(first_pass$opcode == "LOG1"), "has_impacting_arg1"] = TRUE
first_pass[which(first_pass$opcode == "LOG2"), "has_impacting_arg1"] = TRUE
first_pass[which(first_pass$opcode == "LOG3"), "has_impacting_arg1"] = TRUE
first_pass[which(first_pass$opcode == "LOG4"), "has_impacting_arg1"] = TRUE
first_pass[which(first_pass$opcode == "CREATE"), "has_impacting_arg2"] = TRUE
first_pass[which(first_pass$opcode == "RETURN"), "has_impacting_arg1"] = TRUE
first_pass[which(first_pass$opcode == "CREATE2"), "has_impacting_arg2"] = TRUE
first_pass[which(first_pass$opcode == "REVERT"), "has_impacting_arg1"] = TRUE

first_pass$has_impacting <- first_pass$has_impacting_arg0 | first_pass$has_impacting_arg1 | first_pass$has_impacting_arg2
```

```{r, include=FALSE}
args_estimates = data.frame(opcode=character(0),arg=character(0),ns_raw=numeric(0),ns_p=numeric(0),has_impacting=logical(0))
for(i in 1:nrow(first_pass)) {
  opcode_estimates <- first_pass[i,]
  if (!is.na(opcode_estimates[["arg0_ns_raw"]])) {
    args_estimates[nrow(args_estimates) + 1, ] = list(opcode_estimates[["opcode"]], "0", opcode_estimates[["arg0_ns_raw"]], opcode_estimates[["arg0_ns_p"]], opcode_estimates[["has_impacting_arg0"]])
  }
  if (!is.na(opcode_estimates[["arg1_ns_raw"]])) {
    args_estimates[nrow(args_estimates) + 1, ] = list(opcode_estimates[["opcode"]], "1", opcode_estimates[["arg1_ns_raw"]], opcode_estimates[["arg1_ns_p"]], opcode_estimates[["has_impacting_arg1"]])
  }
  if (!is.na(opcode_estimates[["arg2_ns_raw"]])) {
    args_estimates[nrow(args_estimates) + 1, ] = list(opcode_estimates[["opcode"]], "2", opcode_estimates[["arg2_ns_raw"]], opcode_estimates[["arg2_ns_p"]], opcode_estimates[["has_impacting_arg2"]])
  }
}
```

The argument is considered impacting on the gas cost of opcode execution
if its coefficient in the regression model

1. is noticeable comparing to the marginal cost (at least `r paste(impact_ratio, '%')`),
2. has high correlation (`r paste0('Pr(>|t|)=Pr(>|Estimate/Std. Error|)<', p_value_thresh)`).

Moreover, these opcodes are considered having impacting arguments by default as they are explicitly 
included in the current gas cost calculation.

- EXP, arg1
- KECCAK256, arg1
- CALLDATACOPY, arg2
- CODECOPY, arg2
- EXTCODECOPY, arg2
- RETURNDATACOPY, arg2
- MCOPY, arg2
- LOG0, arg1
- LOG1, arg1
- LOG2, arg1
- LOG3, arg1
- LOG4, arg1
- CREATE, arg2
- RETURN, arg1
- CREATE2, arg2
- REVERT, arg1

Below is the listing of arguments impact.

```{r}
if (details) {
  args_estimates
} else {
  args_estimates[which(args_estimates$has_impacting), ]
}
```

The blue graph is the measurements, the red line is the estimated arguments cost shifted by the estimated constant cost of the programs execution.
The default opcodes count is 30.

```{r fig.width=12}
proceed_with_opcodes <- first_pass[which(first_pass$has_impacting), "opcode"]
for(opcode in proceed_with_opcodes) {
  opcode_estimates <- first_pass[which(first_pass$opcode == opcode),]
  if (opcode_estimates[["has_impacting_arg1"]]) {
    slope = opcode_estimates[["arg1_ns_raw"]] * 30
    intercept = opcode_estimates[["intercept"]] + opcode_estimates[["estimate_marginal_ns"]] * 30
    xmax = max(measurements[which(measurements$opcode == opcode & measurements$op_count == 30), "arg1"])
    ymin = min(measurements[which(measurements$opcode == opcode & measurements$op_count == 30), "measure_total_time_ns"], intercept, intercept + slope * xmax)
    ymax = max(measurements[which(measurements$opcode == opcode & measurements$op_count == 30), "measure_total_time_ns"], intercept, intercept + slope * xmax)
    plot(measure_total_time_ns ~ arg1, data=measurements[which(measurements$opcode == opcode & measurements$op_count == 30), ], pch=5, col='blue', ylim=c(ymin*0.95, ymax*1.05))
    title(main = paste(env, opcode, 'arg1', 'opcount 30'))
    abline(a=intercept, b=slope, col="red")
  }
}
```

# Expensive and trivial modes

In some cases an execution of opcode is trivial. For instance DIV x, y for x < y fives 0 without further work.
For selected opcodes we investigate the trivial mode and so the called expensive mode 
when typical algorithm needs to be run fully.


```{r}
first_pass[which(!is.na(first_pass$expensive_ns_raw)), c("opcode", "estimate_marginal_ns", "estimate_marginal_ns_p", "expensive_ns_raw", "expensive_ns_p")]
```

Heat maps help to visualize dependency between two arguments, in particular division into trivial and expensive modes.
Other strong or weak dependencies can be also detected.

```{r, include=FALSE}
# it may be that for opcode with arity == 3 or arity == 2 only 1 arg is examined, use_arg is the arg
plot_args_dependency_1 <- function(df, opcode, use_arg) {
  arg_name = paste0('arg', use_arg)
  aggregate_formula = as.formula(paste0('measure_total_time_ns ~ op_count * ', arg_name))
  df <- aggregate(aggregate_formula, df[which(df$opcode==opcode), ], mean)

  plot_data = df[which(df$op_count == max(df$op_count)), ]

  plot_formula = as.formula(paste0('measure_total_time_ns ~ ', arg_name))
  plot(plot_formula, data=plot_data, pch=19, xlab=arg_name, ylab="measure_total_time_ns")
  title(main=paste(opcode, paste0(c("measure_total_time_ns", arg_name), collapse="~")))
}

# it may be that for opcode with arity == 3 only 2 args are examined, use_args is a list of these two args
plot_args_dependency_2 <- function(df, opcode, use_args) {
  args_names = paste0('arg', use_args)
  args_formula_str = paste0(args_names, collapse=' * ')
  aggregate_formula = as.formula(paste0('measure_total_time_ns ~ op_count * ', args_formula_str))
  df <- aggregate(aggregate_formula, df[which(df$opcode==opcode), ], mean)

  plot_data = df[which(df$op_count == max(df$op_count)), ]
  decreasing_colors = heat.colors(nrow(plot_data))
  plot_data=plot_data[order(plot_data$measure_total_time_ns, decreasing=TRUE), ]
  
  plot(plot_data[, args_names[1]], plot_data[, args_names[2]], col=decreasing_colors, pch=19, xlab=args_names[1], ylab=args_names[2])
  title(main=paste(opcode, paste0(rev(paste0('arg', use_args)), collapse="~")))
}

if (details) {
  proceed_with_opcodes <- first_pass[, "opcode"]
} else {
  proceed_with_opcodes <- first_pass[which(first_pass$has_impacting), "opcode"]
}
```

```{r fig.width=12}
for(opcode in proceed_with_opcodes) {
  working_args <- args_estimates[which(args_estimates$opcode == opcode), "arg"]
  if (length(working_args) == 1) {
    plot_args_dependency_1(measurements, opcode, working_args[[1]])
  } else if (length(working_args) == 2) {
    plot_args_dependency_2(measurements, opcode, working_args)
  }
}
```

# Verification against marginal estimations


In this section we compare opcodes cost obtained in the arguments course with previous estimations obtained in the marginal procedure.

`r if(marginal_estimated_cost_empty){"No marginal estimated cost files given."}`

```{r, include = FALSE}
q <- "SELECT first_pass.opcode, first_pass.estimate_marginal_ns + IFNULL(first_pass.expensive_ns_raw, 0) AS 'opcode_cost(arguments)', marginal_estimated_cost.estimate_marginal_ns AS 'opcode_cost(marginal)' FROM first_pass LEFT JOIN marginal_estimated_cost ON first_pass.opcode = marginal_estimated_cost.op"
compare_marginal <- sqldf(q)
compare_marginal$'rel diff' <- (compare_marginal$'opcode_cost(arguments)' / compare_marginal$'opcode_cost(marginal)') - 1
```

```{r, include = !marginal_estimated_cost_empty}
compare_marginal
```

```{r, incude = FALSE}
if (params$output_estimated_cost != "") {
  write.csv(first_pass, params$output_estimated_cost, quote=FALSE, row.names=FALSE)
}
```
