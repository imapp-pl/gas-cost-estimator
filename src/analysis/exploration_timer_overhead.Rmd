---
title: "R Notebook: exploration of relation of OPCODE measurements with timer overhead measurements"
output: html_notebook
---

## Introductory stuffs
```{r include=FALSE, fig.width=20}
library(sqldf)
library(caTools)

geth_color = rgb(0.1,0.1,0.7,0.5)
geth_time_color = rgb(0.1,0.1,0.7,1)
ma <- function(x, n = 100){stats::filter(x, rep(1 / n, n), sides = 2)}
```

<style>
  .superbigimage{
      overflow-x:scroll;
      white-space: nowrap;
  }
  .superbigimage img{
     max-width: none;
  }
</style>

## Data preparations

Read in the `one_program.csv` as generated by `src/program_generator.py` with `--fullCSV` flag on (and with a single program filtered out manually, we pick `NOT`, `COINBASE` was also tried):
```{r fig.width=20}
setwd("~/sources/imapp/gas-cost-estimator/src")
programs = read.csv("../../local/one_program.csv")
programs$measured_op_position_evmone = programs$measured_op_position + 1
head(programs)
```

Measurements obtained via `cat ../../local/one_program.csv | python3 instrumentation_measurement/measurements.py measure --sampleSize=5000 --nSamples=10 > ../../local/result_geth_timer2_one_program.csv`

```{r fig.width=20}
setwd("~/sources/imapp/gas-cost-estimator/src")
result_geth = read.csv("../../local/result_geth_timer2_one_program.csv")
result_geth_brutal = read.csv("../../local/result_geth_timer2_one_program_brutal.csv")
result_geth$env = "geth"
result_geth_brutal$env = "geth_brutal"
results = rbind(result_geth, result_geth_brutal)
head(results)
```

Combine the two tables to see only times of the measured opcodes.

```{r fig.width=20}
measurements = sqldf("SELECT opcode_measured, sample_id, run_id, measure_all_time_ns, measure_all_timer_time_ns, env
                     FROM results
                     INNER JOIN
                       programs ON(results.program_id = programs.program_id)
                     WHERE
                       (results.instruction_id = programs.measured_op_position AND results.env = 'geth') OR
                       (results.instruction_id = programs.measured_op_position AND results.env = 'geth_brutal')
                     ")

head(measurements)
```

Some initial plots.

**For earlier non-brutal measurement** it can be seen, that there is some relation between the timer's measurement and the OPCODE measurement.
Note that the moving average of the timer measurement isn't interesting - it is too much impacted by the huge outliers, which are also present in timer measurements.

<div class="superbigimage">
```{r fig.width=100, fig.height=7}
non_brutal = measurements[which(measurements$env == "geth"), ]
plot(NULL, xlim=c(1, nrow(non_brutal)), ylim=c(20, 250), main="geth")

lines((non_brutal$measure_all_time_ns), type = "l", col = geth_color)
lines((non_brutal$measure_all_timer_time_ns), type = "l", col = geth_time_color)
lines(ma(non_brutal$measure_all_timer_time_ns), type = "l", col = "red")

```
</div>


After changing the instrumentation method to brutal (without the overhead of a polymorphic `Tracer`), this effect is much weaker.

<div class="superbigimage">
```{r fig.width=100, fig.height=7}
# brutal instrumentation
brutal = measurements[which(measurements$env == "geth_brutal"), ]
plot(NULL, xlim=c(1, nrow(brutal)), ylim=c(20, 250), main="geth_brutal")

lines((brutal$measure_all_time_ns), type = "l", col = geth_color)
lines((brutal$measure_all_timer_time_ns), type = "l", col = geth_time_color)
lines(ma(brutal$measure_all_timer_time_ns), type = "l", col = "red")
```
</div>

Here we do some summary statistics on our data, correlation is there, somewhat.
We'll remove outliers later.

First non-brutal:

```{r}
non_brutal = measurements[which(measurements$env == "geth"), ]

summary(non_brutal$measure_all_timer_time_ns)
boxplot(non_brutal$measure_all_timer_time_ns, outline=FALSE)

summary(non_brutal$measure_all_time_ns)
boxplot(non_brutal$measure_all_time_ns, outline=FALSE)

measurements_sample = non_brutal[sample(nrow(non_brutal), 100), c("measure_all_time_ns", "measure_all_timer_time_ns")]
var(measurements_sample)
cor(measurements_sample)
# cleanup
rm(measurements_sample)
```

Now brutal:

```{r}
brutal = measurements[which(measurements$env == "geth_brutal"), ]

summary(brutal$measure_all_timer_time_ns)
boxplot(brutal$measure_all_timer_time_ns, outline=FALSE)

summary(brutal$measure_all_time_ns)
boxplot(brutal$measure_all_time_ns, outline=FALSE)

measurements_sample = brutal[sample(nrow(measurements), 100), c("measure_all_time_ns", "measure_all_timer_time_ns")]
var(measurements_sample)
cor(measurements_sample)
# cleanup
rm(measurements_sample)
```

Remove outliers here.

```{r}
remove_outliers <- function(df, col, selection_col, selection_val) {
  subset = df[which(df[, selection_col] == selection_val), ]
  print(subset)
  outliers = boxplot(subset[, col], plot=FALSE)$out
  print(outliers)
  no_outliers = df[-which(df[, col] %in% outliers && df[, selection_col] == selection_val), ]
  return(no_outliers)
}

measurements_no_outliers = remove_outliers(measurements, "measure_all_time_ns", "env", "geth")
measurements_no_outliers = remove_outliers(measurements_no_outliers, "measure_all_timer_time_ns", "env", "geth")
measurements_no_outliers = remove_outliers(measurements_no_outliers, "measure_all_time_ns", "env", "geth_brutal")
measurements_no_outliers = remove_outliers(measurements_no_outliers, "measure_all_timer_time_ns", "env", "geth_brutal")
```


Without the outliers we can plot out a sensible scatter plot, This hints that measurements slow on timer coincide with ones slow on the OPCODE.

From here and next sections we gather, that it is just some periodical "slowness" that is impacting all computations.
That's because there is a hint of linear dependency between the two, but with slope > 1, so we're not just "adding" the slow timer overhead, but everything is slower.

```{r}
scatter.smooth(y=measurements_no_outliers$measure_all_time_ns, x=measurements_no_outliers$measure_all_timer_time_ns)
```
Repeat the correlation result, for good measure:

```{r}
measurements_sample = 
  measurements_no_outliers[sample(nrow(measurements_no_outliers), 100), c("measure_all_time_ns", "measure_all_timer_time_ns")]
var(measurements_sample)
cor(measurements_sample)
# cleanup
rm(measurements_sample)
```
Do some normality tests, but we're not going to attach to the linear regression result too much anyway.

```{r}

measurements_sample = 
  measurements_no_outliers[sample(nrow(measurements_no_outliers), 5000), ]

shapiro.test(measurements_sample$measure_all_time_ns)
shapiro.test(log(measurements_sample$measure_all_time_ns))

hist(measurements_no_outliers$measure_all_time_ns, probability=T)
lines(density(measurements_no_outliers$measure_all_time_ns),col=2) 

hist(log(measurements_no_outliers$measure_all_time_ns), probability=T)
lines(density(log(measurements_no_outliers$measure_all_time_ns)),col=2) 

# cleanup
rm(measurements_sample)
```

The linear model seems to be in favor of the linear relation, which is contrary to the concept of the timer being "slow".
Everything is sometimes slower when measured.
The OPCODE measurement seems to increase by 3.5 ns, whenever we increase the timer measurement by 1 ns:

```{r}
linear_model = lm(measure_all_time_ns ~ measure_all_timer_time_ns, data=measurements_no_outliers)
summary(linear_model)
```

## Conclusion

For geth at least, the most that makes sense to consider is to subtract a "running minimum", instead of a fixed minimum.
This tackles the problem with outliers and should leave the OPCODE measurement result clear of the overhead,
adjusting to the periodict "slowness" of the computations.

```{r fig.width=20}
N = 10000
plot(NULL, xlim=c(1, N), ylim=c(20, 150))

lines((measurements$measure_all_time_ns), type = "l", col = geth_color)
lines(runmin(measurements$measure_all_timer_time_ns, k = 50), type = "l", col = geth_time_color)
```

<div class="superbigimage">
```{r fig.width=100, fig.height=7}
N = nrow(measurements)
plot(NULL, xlim=c(1, N), ylim=c(20, 250))

lines((measurements_no_outliers$measure_all_time_ns), type = "l", col = geth_color)
lines(runmin(measurements_no_outliers$measure_all_timer_time_ns, k = 50), type = "l", col = geth_time_color)
```
</div>
