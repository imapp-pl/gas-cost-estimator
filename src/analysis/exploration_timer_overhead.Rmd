---
title: "R Notebook: exploration of relation of OPCODE measurements with timer overhead measurements"
output: html_notebook
---

## Introductory stuffs
```{r include=FALSE, fig.width=20}
library(sqldf)
library(caTools)

geth_color = rgb(0.1,0.1,0.7,0.5)
geth_time_color = rgb(0.1,0.1,0.7,1)
ma <- function(x, n = 100){stats::filter(x, rep(1 / n, n), sides = 2)}
```

<style>
  .superbigimage{
      overflow-x:scroll;
      white-space: nowrap;
  }
  .superbigimage img{
     max-width: none;
  }
</style>

## Data preparations

Read in the `one_program.csv` as generated by `src/program_generator.py` with `--fullCSV` flag on (and with a single program filtered out manually, we pick `NOT`, `COINBASE` was also tried):
```{r fig.width=20}
setwd("~/sources/imapp/gas-cost-estimator/src")
programs = read.csv("../../local/one_program.csv")
programs$measured_op_position_evmone = programs$measured_op_position + 1
head(programs)
```

Measurements obtained via `cat ../../local/one_program.csv | python3 instrumentation_measurement/measurements.py measure --sampleSize=5000 --nSamples=10 > ../../local/result_geth_timer2_one_program.csv`

```{r fig.width=20}
setwd("~/sources/imapp/gas-cost-estimator/src")
result_geth = read.csv("../../local/result_geth_timer2_one_program.csv")
result_geth_brutal = read.csv("../../local/result_geth_timer2_one_program_brutal.csv")
result_geth$env = "geth"
result_geth_brutal$env = "geth_brutal"
results = rbind(result_geth, result_geth_brutal)
head(results)
```

Combine the two tables to see only times of the measured opcodes.

```{r fig.width=20}
measurements = sqldf("SELECT opcode_measured, sample_id, run_id, measure_all_time_ns, measure_all_timer_time_ns, env
                     FROM results
                     INNER JOIN
                       programs ON(results.program_id = programs.program_id)
                     WHERE
                       (results.instruction_id = programs.measured_op_position AND results.env = 'geth') OR
                       (results.instruction_id = programs.measured_op_position AND results.env = 'geth_brutal')
                     ")

head(measurements)
```

Some initial plots.

**For earlier non-brutal measurement** it can be seen, that there is some relation between the timer's measurement and the OPCODE measurement.
Note that the moving average of the timer measurement isn't interesting - it is too much impacted by the huge outliers, which are also present in timer measurements.

<div class="superbigimage">
```{r fig.width=100, fig.height=7}
non_brutal = measurements[which(measurements$env == "geth"), ]
plot(NULL, xlim=c(1, nrow(non_brutal)), ylim=c(20, 250), main="geth")

lines((non_brutal$measure_all_time_ns), type = "l", col = geth_color)
lines((non_brutal$measure_all_timer_time_ns), type = "l", col = geth_time_color)
lines(ma(non_brutal$measure_all_timer_time_ns), type = "l", col = "red")

```
</div>


After changing the instrumentation method to brutal (without the overhead of a polymorphic `Tracer`), this effect is much weaker.
We'll keep on validating this finding in the rest of the notebook.

<div class="superbigimage">
```{r fig.width=100, fig.height=7}
# brutal instrumentation
brutal = measurements[which(measurements$env == "geth_brutal"), ]
plot(NULL, xlim=c(1, nrow(brutal)), ylim=c(20, 250), main="geth_brutal")

lines((brutal$measure_all_time_ns), type = "l", col = geth_color)
lines((brutal$measure_all_timer_time_ns), type = "l", col = geth_time_color)
lines(ma(brutal$measure_all_timer_time_ns), type = "l", col = "red")
```
</div>

Here we do some summary statistics on our data.
We'll remove outliers later.

First non-brutal:

```{r}
non_brutal = measurements[which(measurements$env == "geth"), ]

summary(non_brutal$measure_all_timer_time_ns)
boxplot(non_brutal$measure_all_timer_time_ns, outline=FALSE)

summary(non_brutal$measure_all_time_ns)
boxplot(non_brutal$measure_all_time_ns, outline=FALSE)
```

Now brutal. Observe the much smaller values of mean etc.:

```{r}
brutal = measurements[which(measurements$env == "geth_brutal"), ]

summary(brutal$measure_all_timer_time_ns)
boxplot(brutal$measure_all_timer_time_ns, outline=FALSE)

summary(brutal$measure_all_time_ns)
boxplot(brutal$measure_all_time_ns, outline=FALSE)
```

Remove outliers here.

```{r}
remove_outliers <- function(df, col, selection_col, selection_val) {
  subset = df[which(df[, selection_col] == selection_val), ]
  outliers = boxplot(subset[, col], plot=FALSE)$out
  no_outliers = df[-which(df[, col] %in% outliers & df[, selection_col] == selection_val), ]
  return(no_outliers)
}

measurements_no_outliers = remove_outliers(measurements, "measure_all_time_ns", "env", "geth")
measurements_no_outliers = remove_outliers(measurements_no_outliers, "measure_all_timer_time_ns", "env", "geth")
measurements_no_outliers = remove_outliers(measurements_no_outliers, "measure_all_time_ns", "env", "geth_brutal")
measurements_no_outliers = remove_outliers(measurements_no_outliers, "measure_all_timer_time_ns", "env", "geth_brutal")
```


Without the outliers we can plot out a sensible scatter plot, This hints that measurements slow on timer coincide with ones slow on the OPCODE.

**For non-brutal** From here and next sections we gather, that it is just some periodical "slowness" that is impacting all computations.
That's because there is a hint of linear dependency between the two, but with slope > 1, so we're not just "adding" the slow timer overhead, but everything is slower.

**For brutal** the slope is gone, it seem like the periodic slowness of the overhead measurement was somehow tied to the polymorphic `Tracer` calls.

```{r}
scatter_plot <- function(df, selection_col, selection_val) {
  subset = df[which(df[, selection_col] == selection_val), ]
  scatter.smooth(y=subset$measure_all_time_ns, x=subset$measure_all_timer_time_ns)
}

scatter_plot(measurements_no_outliers, "env", "geth")
scatter_plot(measurements_no_outliers, "env", "geth_brutal")
```

Sampled correlation and normality tests. (We do some normality tests, but we're not going to attach to the linear regression result too much anyway.).

We observe that **brutal** has much less correlation between timer overhead and measurement:

```{r}
cor_norm <- function(df, selection_col, selection_val) {
  subset = df[which(df[, selection_col] == selection_val), ]
  
  sample = subset[sample(nrow(subset), 5000), c("measure_all_time_ns", "measure_all_timer_time_ns")]
  print(var(sample))
  print(cor(sample))
  print(shapiro.test(sample$measure_all_time_ns))
  print(shapiro.test(log(sample$measure_all_time_ns)))

  hist(subset$measure_all_time_ns, probability=T)
  lines(density(subset$measure_all_time_ns),col=2) 
  
  hist(log(subset$measure_all_time_ns), probability=T)
  lines(density(log(subset$measure_all_time_ns)),col=2) 
}

cor_norm(measurements_no_outliers, "env", "geth")
cor_norm(measurements_no_outliers, "env", "geth_brutal")
```

**For non-brutal measurements in geth** the linear model seems to be in favor of the linear relation, which is contrary to the concept of the timer being "slow".
Everything is sometimes slower when measured.
The OPCODE measurement seems to increase by 3.5 ns, whenever we increase the timer measurement by 1 ns.

**For brutal** this relation is gone. The slope is below 1, which kinda makes sense - the timer overhead adds on to the measurement.:

```{r}
linear_model <- function(df, selection_col, selection_val) {
  subset = df[which(df[, selection_col] == selection_val), ]
  
  return(lm(measure_all_time_ns ~ measure_all_timer_time_ns, data=subset))
}
summary(linear_model(measurements_no_outliers, "env", "geth"))
summary(linear_model(measurements_no_outliers, "env", "geth_brutal"))
```

## Conclusion

For geth at least, the most that makes sense to consider is to subtract a "running minimum", instead of a fixed minimum.
This tackles the problem with outliers and should leave the OPCODE measurement result clear of the overhead,
adjusting to the periodic "slowness" of the computations.

**Additional conclusion** is that for `geth` the brutal measurement (don't use the polymorphic `Tracer`) is much better, the measurements are smaller and impact of timer overhead smaller.

Non-brutal:

<div class="superbigimage">
```{r fig.width=100, fig.height=7}
plot_with_runmin <- function(df, selection_col, selection_val) {
  subset = df[which(df[, selection_col] == selection_val), ]
  N = nrow(subset)
  plot(NULL, xlim=c(1, N), ylim=c(20, 250))
  
  lines((subset$measure_all_time_ns), type = "l", col = geth_color)
  lines(runmin(subset$measure_all_timer_time_ns, k = 50), type = "l", col = geth_time_color)
}

plot_with_runmin(measurements_no_outliers, "env", "geth")
```
</div>

Brutal:

<div class="superbigimage">
```{r fig.width=100, fig.height=7}
plot_with_runmin(measurements_no_outliers, "env", "geth_brutal")
```
</div>
