---
title: "R Notebook: estimation of gas costs using the measure marginal method; for Gas Cost Estimator"
output: html_notebook
---

```{r include=FALSE, fig.width=20}
library(sqldf)
library(nlme)
```


## Data preparations

Read in the `programs.csv` as generated by `src/pg_marginal` with `--fullCSV` flag on:
```{r fig.width=20}
setwd("~/sources/imapp/gas-cost-estimator/src")

program_set_codename = "exp"
programs = read.csv(paste("../../local/pg_marginal_", program_set_codename, ".csv", sep=""))
```

Unfortunately `JUMP` and `JUMPI` are currently broken in `geth` (they require a `JUMPDEST`).
Because they work in `evmone` (it prepends `JUMPDEST`) forcefully, we should drop them from the analysis.
Also `RETURNDATACOPY` program generation is broken in general (`return data out of bounds`).

```{r fig.width=20}
clean_programs = function(programs) {
  programs = programs[which(programs$opcode != "JUMP"), ]
  programs = programs[which(programs$opcode != "JUMPI"), ]
  programs = programs[which(programs$opcode != "RETURNDATACOPY"), ]
  
  # necessary to get rid of the factor levels which we just filtered out
  droplevels(programs)
}

programs = clean_programs(programs)

head(programs)
```

Read in the `result_*.csv` as generated by `src/measurements.py`. 

Invocation similar to: `sudo docker run   --rm   --privileged --security-opt seccomp:unconfined -v /home/ubuntu/pdobacz/local:/srv/local  -it gas-cost-estimator/geth_total sh -c "cd src && cat /srv/local/pg_marginal_exp_c50_shuffle.csv | python3 instrumentation_measurement/measurements.py measure --evm geth --mode total --sampleSize=50 --nSamples=4 > /srv/local/geth_pg_marginal_exp_c50_shuffle_total_50_4.csv"`. 

```{r fig.width=20}
setwd("~/sources/imapp/gas-cost-estimator/src")

load_data_set <- function(env, program_set_codename, measurement_codename) {
  setwd("~/sources/imapp/gas-cost-estimator/src")
  data_set_codename = paste(program_set_codename, "_", measurement_codename, sep="")
  filepath = paste("../../local/", env, "_pg_marginal_", data_set_codename, ".csv", sep="")
  result = read.csv(filepath)
  result$env = env
  return(result)
}
result_geth = load_data_set("geth", "exp", "total_50_4")
result_evmone = load_data_set("evmone", "exp", "total_50_4")
results = rbind(result_geth, result_evmone)
head(results)
```

Combine the two tables to identify the programs and measured OPCODEs.

```{r fig.width=20}
measurements = sqldf("SELECT opcode, op_count, sample_id, run_id, measure_total_time_ns, env, results.program_id
                     FROM results
                     INNER JOIN
                       programs ON(results.program_id = programs.program_id)
                     ")
head(measurements)
```

### Remove outliers

Removing or not of the outliers has a large impact on the final results.
It seems that for `EXP` and `evmone` there are many outliers in the mid-low `op_count` samples.
This effectively "leverages" the estimated slope downwards, pretending `EXP`'s `evmone` to be cheaper than it really seems to be.

Switch `removed_outliers` to `FALSE` to see the comparison.

```{r}
remove_outliers <- function(df, col) {
  outliers = boxplot(df[, col] ~ df[, 'op_count'] + df[, 'env'] + df[, 'opcode'], plot=FALSE)$out
  no_outliers = df[-which(df[, col] %in% outliers), ]
  return(no_outliers)
}

removed_outliers = TRUE

if (removed_outliers) {
  measurements = remove_outliers(measurements, 'measure_total_time_ns')
}

head(measurements)
```

### Trim the initial values

Commented out because not necessary.

```{r}
# measurements = measurements[-(which(measurements$op_count < 15)), ]
```


```{r fig.width=15}
boxplot(measure_total_time_ns ~ op_count, data=measurements[which(measurements$env == 'geth'), ], las=2, outline=removed_outliers)
boxplot(measure_total_time_ns ~ op_count, data=measurements[which(measurements$env == 'evmone'), ], las=2, outline=removed_outliers)
```

```{r}
measurements_mean = aggregate(measure_total_time_ns ~ op_count * env, measurements, mean)
  
scatter.smooth(measurements_mean[which(measurements_mean$env == 'geth'), 'op_count'], measurements_mean[which(measurements_mean$env == 'geth'), 'measure_total_time_ns'])
scatter.smooth(measurements_mean[which(measurements_mean$env == 'evmone'), 'op_count'], measurements_mean[which(measurements_mean$env == 'evmone'), 'measure_total_time_ns'])
```

```{r}
model_mean_geth = lm(measure_total_time_ns ~ op_count, data=measurements_mean[which(measurements_mean$env == 'geth'), ])
model_mean_evmone = lm(measure_total_time_ns ~ op_count, data=measurements_mean[which(measurements_mean$env == 'evmone'), ])
summary(model_mean_geth)
summary(model_mean_evmone)
```

```{r}
model_geth = lm(measure_total_time_ns ~ op_count, data=measurements[which(measurements$env == 'geth'), ])
model_evmone = lm(measure_total_time_ns ~ op_count, data=measurements[which(measurements$env == 'evmone'), ])
summary(model_geth)
summary(model_evmone)
```


```{r fig.width=15}
par(mfrow=c(4,4))
plot(model_mean_geth)
plot(model_mean_evmone)
plot(model_geth)
plot(model_evmone)
```

```{r}
programs_for_compute <- function(program_set_codename) {
  setwd("~/sources/imapp/gas-cost-estimator/src")
  programs = read.csv(paste("../../local/pg_marginal_", program_set_codename, ".csv", sep=""))
  clean_programs(programs)
}

compute_all <- function(programs, results, opcode, env, removed_outliers, max_op_count, mod_op_count, plots) {
  if (missing(plots)) {
    plots = "scatter"
  }
  if (missing(max_op_count)) {
    max_op_count_condition = ""
  } else {
    max_op_count_condition = paste(" AND op_count < ", max_op_count, sep="")
  }
  if (missing(mod_op_count)) {
    mod_op_count_condition = ""
  } else {
    mod_op_count_condition = paste(" AND op_count % ", mod_op_count, " = 0", sep="")
  }
  print(c(opcode, env))
  
  measurements = sqldf(paste("SELECT opcode, op_count, sample_id, run_id, measure_total_time_ns, env, results.program_id
                       FROM results
                       INNER JOIN
                         programs ON(results.program_id = programs.program_id)
                       WHERE opcode = '", opcode, "'",
                       max_op_count_condition, mod_op_count_condition, sep=""))
  if (removed_outliers) {
    measurements = remove_outliers(measurements, 'measure_total_time_ns')
  }
  measurements_mean = aggregate(measure_total_time_ns ~ op_count * env, measurements, mean)
  
  model_mean = lm(measure_total_time_ns ~ op_count, data=measurements_mean)
  print(summary(model_mean))
  
  # Let's leave non-mean model out, it's not useful on top of the mean model
  # model = lm(measure_total_time_ns ~ op_count, data=measurements)
  # print(summary(model))
  
  if (plots == "scatter" | plots == "all") {
    par(mfrow=c(1,2))
    boxplot(measure_total_time_ns ~ op_count, data=measurements, las=2, outline=removed_outliers)
    title(main=env)
    scatter.smooth(measurements_mean[, 'op_count'], measurements_mean[, 'measure_total_time_ns'])
    title(main=opcode)
  }
  if (plots == "diagnostics" | plots == "all") {
    par(mfrow=c(2,2))
    plot(model_mean)
    
    # Let's leave non-mean model out, it's not useful on top of the mean model
    # plot(model)
  
    # this is here to not have the order of results confused in the rendered output
    # Sys.sleep(1)
  }
  
  (model_mean$coefficients[['op_count']])
}
```

```{r fig.width=12}
compute_all(programs_for_compute("exp"), load_data_set("evmone", "exp", "total_50_4"), "EXP", "evmone", TRUE, mod_op_count=10)
```

```{r fig.width=12}
extract_opcodes <- function(program_set_codename) {
  setwd("~/sources/imapp/gas-cost-estimator/src")
  programs = read.csv(paste("../../local/pg_marginal_", program_set_codename, ".csv", sep=""))
  programs = clean_programs(programs)
  unique(programs$opcode)
}

# We use 50 growing programs, instead of the initial 200:
# 1. it appears to stabilize fast enough, after we have begun randomizing the order of programs to avoid impact of periodic slowness
# 2. `geth` is very slow to calculate and blows the CPU allowance on our AWS machine, if we do 200
all_opcodes = extract_opcodes("arithmetic_c50")
estimates = data.frame(matrix(ncol = 3, nrow = 0))
colnames(estimates) <- c('op', 'estimate_marginal_ns', 'env')
```
### Final computation for all OPCODEs

`_comb_` stands for "combined". The `EXP` measurement has been redone for the input `0xa1` instead of `0x20`, which caused the estimation to be underpriced (as seen in the `validation` notebook).
This in turn skewed the result enough for `geth` to get a significant, negative intercept.
After adjusting the input higher, the intercept is "less" significant, but still present.
`EXP` looks still somewhat underpriced - we need to parametrize its arguments properly.

```{r}
estimates = estimates[which(estimates$env != 'evmone'), ]
programs = programs_for_compute("arithmetic_comb_c50_shuffle")
results = load_data_set("evmone", "arithmetic_comb_c50_shuffle", "total_50_4")
for (opcode in all_opcodes) {
  estimate = compute_all(programs, results, opcode, "evmone", TRUE)
  estimates[nrow(estimates) + 1, ] = c(opcode, estimate, 'evmone')
}
```

```{r}
estimates = estimates[which(estimates$env != 'geth'), ]
programs = programs_for_compute("arithmetic_comb_c50_shuffle")
results = load_data_set("geth", "arithmetic_comb_c50_shuffle", "total_50_4")
for (opcode in all_opcodes) {
  estimate = compute_all(programs, results, opcode, "geth", TRUE, mod_op_count=5)
  estimates[nrow(estimates) + 1, ] = c(opcode, estimate, 'geth')
}
```

```{r}
print(all_opcodes)
```

```{r}
setwd("~/sources/imapp/gas-cost-estimator/src")
write.csv(estimates, "../../local/marginal_estimated_cost.csv", quote=FALSE, row.names=FALSE)
```

