---
title: "R Notebook: estimation of gas costs using the measure marginal method; for Gas Cost Estimator"
output: html_document
---

```{r include=FALSE, fig.width=20}
library(sqldf)
library(nlme)
library(mixtools)

# prevent scientific notation
options(scipen = 100)
```

## Data preparations

`programs.csv` as generated by `pg_marginal.py` with `--fullCSV` flag on.
`result_*.csv` as generated by `src/measurements.py`. 
Invocation similar to: `make measure EVM=geth VOLUME_DIR=/home/user/sources/imapp/local PROGRAMS=pg_marginal_full5_c50_step1_shuffle SAMPLESIZE=50 NSAMPLES=4`. 

```{r fig.width=20}
setwd("~/sources/imapp/gas-cost-estimator/src")
program_set_codename = "full5_c50_step1_shuffle"
programs = read.csv(paste("../../local/pg_marginal_", program_set_codename, ".csv", sep=""))

load_data_set <- function(env, measurement_codename) {
  setwd("~/sources/imapp/gas-cost-estimator/src")
  data_set_codename = paste(program_set_codename, "_", measurement_codename, sep="")
  filepath = paste("../../local/", env, "_pg_marginal_", data_set_codename, ".csv", sep="")
  result = read.csv(filepath)
  result$env = env
  return(result)
}
# measurement_codename = "50_4"
measurement_codename = "50_4_lenovo"

result_geth = load_data_set("geth", measurement_codename)
result_evmone = load_data_set("evmone", measurement_codename)
# TODO geth short-circuits zero length programs, resulting in zero timing somehow. Drop these more elegantly, not based on measure_total_time_ns
result_geth = result_geth[which(result_geth$measure_total_time_ns != 0), ]
results = rbind(result_evmone, result_geth)
```
```{r}
measurements = sqldf("SELECT opcode, op_count, sample_id, run_id, measure_total_time_ns, env, results.program_id
                     FROM results
                     INNER JOIN
                       programs ON(results.program_id = programs.program_id)")
```

### Remove outliers

Removing or not of the outliers has a large impact on the final results.
It seems that for `EXP` and `evmone` there are many outliers in the mid-low `op_count` samples.
This effectively "leverages" the estimated slope downwards, pretending `EXP`'s `evmone` to be cheaper than it really seems to be.

Switch `removed_outliers` to `FALSE` to see the comparison.

```{r fig.width=15}
remove_outliers <- function(df, col) {
  boxplot_result = boxplot(df[, col] ~ df[, 'op_count'] + df[, 'env'] + df[, 'opcode'], plot=FALSE)
  outliers = boxplot_result$out
  names = boxplot_result$names[boxplot_result$group]
  all_row_identifiers = paste(df[, col], df[, 'op_count'], df[, 'env'], df[, 'opcode'], sep='.')
  outlier_row_identifiers = paste(outliers, names, sep='.')
  no_outliers = df[-which(all_row_identifiers %in% outlier_row_identifiers), ]
  return(no_outliers)
}

removed_outliers = TRUE

if (removed_outliers) {
  measurements = remove_outliers(measurements, 'measure_total_time_ns')
}
```

```{r}
correct_bimodal <- function(measurements) {
  mix_model = normalmixEM(measurements$measure_total_time_ns)
  print(summary(mix_model))
  plot(mix_model,which=2)
  mode_distance = abs(mix_model$mu[2] - mix_model$mu[1])
  mode_midpoint = (mix_model$mu[2] + mix_model$mu[1]) / 2
  over_threshold = which(measurements$measure_total_time_ns > mode_midpoint)
  measurements[over_threshold, "measure_total_time_ns"] = measurements[over_threshold, "measure_total_time_ns"] - mode_distance
    
  return(measurements)
}
```

```{r}
compute_all <- function(measurements, opcode, env, removed_outliers, plots, bimodal_opcodes) {
  if (missing(bimodal_opcodes)) {
    bimodal_opcodes = c()
  }
  if (missing(plots)) {
    plots = "scatter"
  }
  print(c(opcode, env))
  
  measurements = measurements[which(measurements$opcode==opcode & measurements$env==env),]
  
  if (opcode %in% bimodal_opcodes) {
    measurements = correct_bimodal(measurements)
  }
  
  measurements_mean = aggregate(measure_total_time_ns ~ op_count * env, measurements, mean)
  
  model_mean = lm(measure_total_time_ns ~ op_count, data=measurements_mean)
  print(summary(model_mean))
  
  if (plots == "scatter" | plots == "all") {
    par(mfrow=c(1,2))
    boxplot(measure_total_time_ns ~ op_count, data=measurements, las=2, outline=removed_outliers)
    title(main=env)
    scatter.smooth(measurements_mean[, 'op_count'], measurements_mean[, 'measure_total_time_ns'])
    title(main=opcode)
  }
  if (plots == "diagnostics" | plots == "all") {
    par(mfrow=c(2,2))
    plot(model_mean)
  }
  
  (model_mean$coefficients[['op_count']])
}
```

```{r fig.width=12}
extract_opcodes <- function() {
  unique(programs$opcode)
}

# We use 50 growing programs, instead of the initial 200:
# 1. it appears to stabilize fast enough, after we have begun randomizing the order of programs to avoid impact of periodic slowness
# 2. `geth` is very slow to calculate and blows the CPU allowance on our AWS machine, if we do 200
# 3. for `openethereum` we should be using use programs with 0-200 increasing `op_count`, otherwise the model doesn't capture the trend. Possibly, this will be resolved by dropping `openethereum`
all_opcodes = extract_opcodes()
estimates = data.frame(matrix(ncol = 3, nrow = 0))
colnames(estimates) <- c('op', 'estimate_marginal_ns', 'env')
```

### Final computation for all OPCODEs

```{r}
estimates = estimates[which(estimates$env != 'geth'), ]
for (opcode in all_opcodes) {
  estimate = compute_all(measurements, opcode, "geth", TRUE)
  estimates[nrow(estimates) + 1, ] = c(opcode, estimate, 'geth')
}
```

```{r}
evmone_bimodals = all_opcodes[which(grepl("PUSH", all_opcodes) & all_opcodes != "PUSH1" | all_opcodes == "JUMP")]
estimates = estimates[which(estimates$env != 'evmone'), ]
for (opcode in all_opcodes) {
  estimate = compute_all(measurements, opcode, "evmone", TRUE, bimodal_opcodes=evmone_bimodals)
  estimates[nrow(estimates) + 1, ] = c(opcode, estimate, 'evmone')
}
```

### Export the results

```{r}
setwd("~/sources/imapp/gas-cost-estimator/src")
write.csv(estimates, "../../local/marginal_estimated_cost.csv", quote=FALSE, row.names=FALSE)
```

