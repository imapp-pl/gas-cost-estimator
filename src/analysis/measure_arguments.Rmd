---
title: "R Notebook: estimation of impact of arguments on gas costs; for Gas Cost Estimator"
output: html_document
---
In this script we conduct the estimation for the `measure_arguments` approach.

```{r, setup, include=FALSE}
# NOTE: change this to your respective path
knitr::opts_knit$set(root.dir = '~/sources/imapp/gas-cost-estimator/src')
source('common.R')
```

## Data preparations

`programs.csv` as generated by `pg_arguments.py` with `--fullCSV` flag on:

```{r fig.width=20}
setwd("~/sources/imapp/gas-cost-estimator/src")

# The program set is 200 programs, with the count of measured OPCODE increases twice in steps of 15,
# so we have a program with 0, 15, and 30 measured OPCODEs 
program_set_codename = "pg_arguments_full5_c200_opc15x2"
programs = read.csv(paste("../../local/", program_set_codename, ".csv", sep=""))
```

`result_*.csv` as generated by `src/measurements.py`.
Invocation similar to: `make measure EVM=geth VOLUME_DIR=/home/user/sources/imapp/local PROGRAMS=pg_arguments_full5_c200_opc15x2 SAMPLESIZE=50 NSAMPLES=1`. 

```{r fig.width=20}
suffix = ""
# suffix = "_lenovo"
measurement_codename = paste0("50_1", suffix)

result_geth = load_data_set("geth", program_set_codename, measurement_codename)
result_evmone = load_data_set("evmone", program_set_codename, measurement_codename)
# TODO geth short-circuits zero length programs, resulting in zero timing somehow. Drop these more elegantly, not based on measure_total_time_ns
result_geth = result_geth[which(result_geth$measure_total_time_ns != 0), ]
all_envs = c("geth", "evmone")
results = rbind(result_evmone, result_geth)
```

### Functions


```{r}
# Extracts all OPCODEs from the `programs` data frame of the given arity (args taken off the stack).
extract_opcodes <- function(arity) {
  if (!missing(arity)) {
    if (arity == 0) {
      programs = programs[which(is.na(programs$arg0) & is.na(programs$arg1) & is.na(programs$arg2)), ]
    }
    if (arity == 1) {
      programs = programs[which(!is.na(programs$arg0) & is.na(programs$arg1) & is.na(programs$arg2)), ]
    }
    if (arity == 2) {
      programs = programs[which(!is.na(programs$arg1) & is.na(programs$arg2)), ]
    }
    if (arity == 3) {
      programs = programs[which(!is.na(programs$arg2)), ]
    }
  }
  unique(programs$opcode)
}
```

```{r}
all_opcodes = extract_opcodes()
nullary_opcodes = extract_opcodes(0)
unary_opcodes = extract_opcodes(1)
binary_opcodes = extract_opcodes(2)
ternary_opcodes = extract_opcodes(3)
div_opcodes = c('DIV', 'MOD', 'SDIV', 'SMOD')

all_envs = c('geth', 'evmone')
```

Combine these data frames into our main `measurements`, which will combine the measurements and the traits of the measured programs.

```{r fig.width=20}
measurements = sqldf("SELECT opcode, op_count, arg0, arg1, arg2, sample_id, run_id, measure_total_time_ns, env, results.program_id
                     FROM results
                     INNER JOIN
                       programs ON(results.program_id = programs.program_id)
                     ")
measurements$opcode = factor(measurements$opcode, levels=unique(programs$opcode))
head(measurements)
```

```{r}
measurements$expensive = NA
measurements[which(measurements$opcode %in% div_opcodes), ]$expensive =
  measurements[which(measurements$opcode %in% div_opcodes), ]$arg0 >
  measurements[which(measurements$opcode %in% div_opcodes), ]$arg1
# remember that argX is the byte-size of the argument in these measurements
measurements[which(measurements$opcode == 'ADDMOD'), ]$expensive =
  8**measurements[which(measurements$opcode == 'ADDMOD'), ]$arg0 +
  8**measurements[which(measurements$opcode == 'ADDMOD'), ]$arg1 > 
  8**measurements[which(measurements$opcode == 'ADDMOD'), ]$arg2
measurements[which(measurements$opcode == 'MULMOD'), ]$expensive =
  measurements[which(measurements$opcode == 'MULMOD'), ]$arg0 +
  measurements[which(measurements$opcode == 'MULMOD'), ]$arg1 >
  measurements[which(measurements$opcode == 'MULMOD'), ]$arg2
```


```{r fig.width=18, fig.height=6}
removed_outliers = TRUE

if (removed_outliers) {
  measurements = remove_compare_outliers(measurements, 'measure_total_time_ns', all_envs)
}
```

## Models

Notes:
1. Outliers need to be removed
2. The `argX:op_count` interactions measure the impact on the OPCODE
3. The `argX` are just auxiliary variables added to exclude the effect of cheaper/more expensive PUSHes. We only want to extract the effect of the argument on the measured OPCODE repeated `op_count` times.

```{r}
# Every `arg` coefficient represents the impact of the argument's byte size growing by 1.
# We treat as impactful the arguments where p-value is effectively zero. The previous approach was:
# Treat as impactful the arguments, where:
# 1. The estimate is significant with confidence 0.001
# 2. The increase of arg's byte size by 1 will increase the cost by more than 1%
# but it turned out to be much less stable in practice.
p_value_thresh = 1e-30
# p_value_thresh = 0.001
impact_ratio = 0.00
# impact_ratio = 0.01

arg_lm <- function(df, opcode, env, formula) {
  data = df[which(df$opcode==opcode & df$env==env), ]
  lm(formula, data=data)
}

# Adds the results from the estimated `model` to the `results_df` data frame.
# You need to provide the corresponding `opcode`, `env` and `arity`.
# `results_df` is assumed to have the columns as the `first_pass` data frame has (see below)
add_arg_results <- function(model, opcode, env, results_df, arity) {
  stopifnot(arity > 0)

  all_coefficients = summary(model)$coefficients
  arg_coefficients = all_coefficients[!(row.names(all_coefficients) %in% c("op_count", "(Intercept)", "arg0", "arg1", "arg2")),]
  pure_op_count_coeff = all_coefficients["op_count", 1]
  # will be filled if any is impacting
  args_ns = c(NA, NA, NA)
  # will be always if arg present
  args_ns_raw = c(NA, NA, NA)
  args_ns_p = c(NA, NA, NA)

  if (arity == 1) {
    # there's only one arg coefficient here, silly R forces us to take a special case path...
    has_significant = arg_coefficients[4] < p_value_thresh
  
    if (has_significant) {
      coefficient_impact = abs(arg_coefficients[1])
      has_impacting = has_significant & coefficient_impact > pure_op_count_coeff * impact_ratio
    } else {
      has_impacting = FALSE
    }
    if (has_impacting) {
      args_ns[1] = arg_coefficients[1]
    }
    args_ns_raw[1] = arg_coefficients[1]
    args_ns_p[1] = arg_coefficients[4]
  } else {
    significant = arg_coefficients[, 4] < p_value_thresh
    has_significant = length(which(significant)) > 0
  
    coefficient_impact = abs(arg_coefficients[, 1])
    can_impact = significant & coefficient_impact > pure_op_count_coeff * impact_ratio
    has_impacting = length(which(can_impact)) > 0
    args_ns[which(can_impact)] = arg_coefficients[which(can_impact), 1]
    args_ns_raw[1:arity] = arg_coefficients[1:arity, 1]
    args_ns_p[1:arity] = arg_coefficients[1:arity, 4]
  }
  
  # NAs for the "expensive" arg columns. See above for the columns layout
  results_df[nrow(results_df) + 1, ] = c(opcode, env, has_significant, has_impacting, pure_op_count_coeff, args_ns, NA, args_ns_raw, NA, args_ns_p, NA)
  return(results_df)
}

# Adds the results from the estimated `model` to the `results_df` data frame, where the model is
# specifically the one gauged towards the "division" OPCODEs like `DIV`.
# See also `add_arg_results`
add_arg_expensive_results <- function(model, opcode, env, results_df, arity) {
  stopifnot(arity > 0)

  all_coefficients = summary(model)$coefficients
  pure_op_count_coeff = all_coefficients["op_count", 1]
  expensive = NA
  
  # there's only one arg coefficient here, silly R forces us to take a special case path...
  has_significant = all_coefficients['op_count:expensiveTRUE', 4] < p_value_thresh

  if (has_significant) {
    coefficient_impact = abs(all_coefficients['op_count:expensiveTRUE', 1])
    has_impacting = has_significant & coefficient_impact > pure_op_count_coeff * impact_ratio
  } else {
    has_impacting = FALSE
  }
  if (has_impacting) {
    expensive = all_coefficients['op_count:expensiveTRUE', 1]
  }
  expensive_raw = all_coefficients['op_count:expensiveTRUE', 1]
  expensive_p = all_coefficients['op_count:expensiveTRUE', 4]
  results_df[which(results_df$opcode == opcode & results_df$env == env), 'expensive_ns'] = expensive
  results_df[which(results_df$opcode == opcode & results_df$env == env), 'expensive_ns_raw'] = expensive_raw
  results_df[which(results_df$opcode == opcode & results_df$env == env), 'expensive_ns_p'] = expensive_p
  return(results_df)
}

# Goes through all the families of OPCODEs and fits and displays their respective `measure_arguments`
# models.
# Results are gathered in a common `results_df` data frame.
analyze_for_env <- function(df, results_df, env) {
  for (opcode in unary_opcodes) {
    model = arg_lm(df, opcode, env, measure_total_time_ns ~ op_count + arg0 + arg0:op_count)
    print(c(opcode, env))
    print(summary(model))
    results_df = add_arg_results(model, opcode, env, results_df, 1)
  }
  for (opcode in binary_opcodes) {
    model = arg_lm(df, opcode, env, measure_total_time_ns ~ op_count + arg0 + arg1 + arg0:op_count + arg1:op_count)
    print(c(opcode, env))
    print(summary(model))
    results_df = add_arg_results(model, opcode, env, results_df, 2)
  }
  for (opcode in ternary_opcodes) {
    model = arg_lm(df, opcode, env, measure_total_time_ns ~ op_count + arg0 + arg1 + arg2 + arg0:op_count + arg1:op_count + arg2:op_count)
    print(c(opcode, env))
    print(summary(model))
    results_df = add_arg_results(model, opcode, env, results_df, 3)
  }
  for (opcode in div_opcodes) {
    model = arg_lm(df, opcode, env, measure_total_time_ns ~ op_count + arg0 + arg1 + expensive:op_count)
    print(c(opcode, env))
    print(summary(model))
    results_df = add_arg_expensive_results(model, opcode, env, results_df, 2)
  }
  for (opcode in c('ADDMOD', 'MULMOD')) {
    model = arg_lm(df, opcode, env, measure_total_time_ns ~ op_count + arg0 + arg1 + arg2 + expensive:op_count)
    print(c(opcode, env))
    print(summary(model))
    results_df = add_arg_expensive_results(model, opcode, env, results_df, 3)
  }
  return(results_df)
}
```

This is the so-called "first-pass" at the estimation procedure, where we estimated all possible argument impact variables
for all OPCODEs.
We gather all the results in the `first_pass` table, inspect this to see where the arguments turned out to be significantly impacting the computation cost.

```{r}
first_pass = data.frame(matrix(ncol = 17, nrow = 0))
colnames(first_pass) <- c('opcode', 'env', 'has_significant', 'has_impacting', 'estimate_marginal_ns',
                          'arg0_ns', 'arg1_ns', 'arg2_ns', 'expensive_ns',
                          'arg0_ns_raw', 'arg1_ns_raw', 'arg2_ns_raw', 'expensive_ns_raw',
                          'arg0_ns_p', 'arg1_ns_p', 'arg2_ns_p',  'expensive_ns_p')

first_pass = analyze_for_env(measurements, first_pass, 'geth')
first_pass = analyze_for_env(measurements, first_pass, 'evmone')

proceed_with_opcodes = unique(first_pass[which(first_pass$has_impacting == 'TRUE'), 'opcode'])

models_with_args_automatic = first_pass[which(first_pass$has_impacting == 'TRUE'), c('opcode', 'env')]
models_with_expensive_automatic = first_pass[which(!is.na(first_pass$expensive_ns)), c('opcode', 'env')]

first_pass[which(first_pass$has_impacting == 'TRUE'), ]
```

We inspect the automatic choice of models, but then coerce the choice to a fixed list.
We drop the division OPCODEs (`DIV` etc.), because their arguments only seem to have an indirect impact
via the fact that x / y is trivial if x < y. This makes the `DIV(x, y)` appear costlier for large x
and cheaper for large y.

```{r}
models_with_args = data.frame(opcode="EXP", env="geth")
models_with_args = rbind(models_with_args, data.frame(opcode="EXP", env="evmone"))
models_with_args = rbind(models_with_args, data.frame(opcode="CALLDATACOPY", env="geth"))
models_with_args = rbind(models_with_args, data.frame(opcode="CALLDATACOPY", env="evmone"))
models_with_args = rbind(models_with_args, data.frame(opcode="CODECOPY", env="geth"))
models_with_args = rbind(models_with_args, data.frame(opcode="CODECOPY", env="evmone"))
models_with_args = rbind(models_with_args, data.frame(opcode="RETURNDATACOPY", env="geth"))
models_with_args = rbind(models_with_args, data.frame(opcode="RETURNDATACOPY", env="evmone"))
models_with_expensive = data.frame(opcode="DIV", env="geth")
models_with_expensive = rbind(models_with_expensive, data.frame(opcode="DIV", env="evmone"))
models_with_expensive = rbind(models_with_expensive, data.frame(opcode="SDIV", env="geth"))
models_with_expensive = rbind(models_with_expensive, data.frame(opcode="SDIV", env="evmone"))
models_with_expensive = rbind(models_with_expensive, data.frame(opcode="MOD", env="geth"))
models_with_expensive = rbind(models_with_expensive, data.frame(opcode="MOD", env="evmone"))
models_with_expensive = rbind(models_with_expensive, data.frame(opcode="SMOD", env="geth"))
models_with_expensive = rbind(models_with_expensive, data.frame(opcode="SMOD", env="evmone"))
models_with_expensive = rbind(models_with_expensive, data.frame(opcode="ADDMOD", env="geth"))
models_with_expensive = rbind(models_with_expensive, data.frame(opcode="ADDMOD", env="evmone"))
models_with_expensive = rbind(models_with_expensive, data.frame(opcode="MULMOD", env="geth"))
models_with_expensive = rbind(models_with_expensive, data.frame(opcode="MULMOD", env="evmone"))
```

## Detailed analysis for selected OPCODEs

```{r fig.width=15}
validation_plot <- function(df, opcode, env, argcol) {
  par(mfrow=c(5,7))
  for (a in 1:32) {
    by_argcol_data = df[which(df$opcode==opcode & df$env==env & df[, argcol]==a), ]
    if (nrow(by_argcol_data) > 0) {
      boxplot(measure_total_time_ns ~ op_count, data=by_argcol_data)
    } else {
      plot.new()
    }
    title(main=paste(opcode, env, argcol, a, sep=', '))
  }
  par(mfrow=c(1,1))
  boxplot(as.formula(paste('measure_total_time_ns ~ ', argcol, sep='')), data=df[which(df$opcode==opcode & df$env==env & df$op_count==max(df$op_count)), ])
}
```

We go through all the OPCODEs which turned out to have impacting arguments in the automatic discrimination procedure, and we plot some validation plots to inspect these relationships.

```{r}
# Takes the results data frame and checks which argument indices (0, 1, etc.)
# turned out to be impacting
get_impact_args_for <- function(df, opcode, env) {
  if (opcode %in% nullary_opcodes) {
    return(c())
  }
  args = c()
  for (n in 0:2) {
    argname = paste0('arg', n, '_ns')
    if (!is.na(df[which(df$opcode==opcode & df$env==env), argname])) {
      args = c(n, args)
    }
  }
  return(rev(args))
}

# same as `get_impact_args_for` but gets all the argument indices
get_args_for <- function(df, opcode, env) {
  if (opcode %in% unary_opcodes) {
    c(0)
  } else if (opcode %in% binary_opcodes) {
    c(0, 1)
  } else if (opcode %in% ternary_opcodes) {
    c(0, 1, 2)
  }
}

# Builds a final model formula to estimate, based on whether the arguments
# came out impactful from the automatic discrimination process.
get_model_formula_for <- function(df, opcode, env) {
  args = get_args_for(df, opcode, env)
  argnames = paste0('arg', args)
  args_formula = paste0(argnames, collapse=' + ')
  
  impact_args = get_impact_args_for(df, opcode, env)
  if (opcode %in% nullary_opcodes) {
    as.formula('measure_total_time_ns ~ op_count')
  } else if (is.null(impact_args)) {
    as.formula(paste0('measure_total_time_ns ~ op_count +  ', args_formula))
  } else {
  arg_op_count_names = paste0('arg', impact_args, ':op_count')
  arg_op_counts_formula = paste0(arg_op_count_names, collapse=' + ')
  as.formula(paste0('measure_total_time_ns ~ op_count +  ', args_formula, ' + ', arg_op_counts_formula))
  }
}

# Same as `get_model_formula_for` but gauged towards the division OPCODEs specifically.
get_expensive_model_formula_for <- function(df, opcode, env) {
  args = get_args_for(df, opcode, env)
  argnames = paste0('arg', args)
  args_formula = paste0(argnames, collapse=' + ')
  as.formula(paste0('measure_total_time_ns ~ op_count +  ', args_formula, ' + expensive:op_count'))
}

# Same as `get_model_formula_for` but returns the formula to provide the `aggregate` function with.
get_aggregate_formula_for <- function(df, opcode, env) {
  args = get_args_for(df, opcode, env)
  argnames = paste0('arg', args)
  args_formula = paste0(argnames, collapse=' * ')
  as.formula(paste0('measure_total_time_ns ~ op_count * env * opcode * ', args_formula))
}

# Presents the diagnostic plots for a given slice of the data
plot_model <- function(df, opcode, env, use_mean) {
  if (missing(use_mean)) {
    use_mean = FALSE
  }
  if (use_mean) {
    df = aggregate(get_aggregate_formula_for(df, opcode, env), measurements[which(df$opcode==opcode & df$env==env), ], mean, na.action=na.pass)
  }
  model = arg_lm(df, opcode, env, get_model_formula_for(first_pass, opcode, env))
  print(c(opcode, env))
  print(summary(model))
  
  par(mfrow=c(2,2))
  plot(model)
  
  validation_plot(df, opcode, env, 'arg0')
  if (opcode %in% c(binary_opcodes, ternary_opcodes)) {
    validation_plot(df, opcode, env, 'arg1')
  }
  if (opcode %in% ternary_opcodes) {
    validation_plot(df, opcode, env, 'arg2')
  }
  
  plot_data = df[which(df$env == env & df$opcode == opcode & df$op_count == max(df$op_count)), ]
  if (opcode %in% binary_opcodes) {
    par(mfrow=c(1,1))
    
    decreasing_colors = heat.colors(nrow(plot_data))
    plot_data=plot_data[order(plot_data$measure_total_time_ns, decreasing=TRUE), ]
    with(plot_data, plot(arg0, arg1, col=decreasing_colors, pch=19))
  }
  title(main=paste(opcode, env))
}
```

Using the functions defined above, we proceed to plot the diagnostic plots of the arguments models

```{r fig.width=10}
for (env in all_envs) {
  for (opcode in proceed_with_opcodes) {
    plot_model(measurements, opcode, env, use_mean=TRUE)
  } 
}
```

### Producing the final estimates

We'd like to only estimate using the arg-variables in models, where this actually matters to avoid spurious impact of insignificant variables.

We'll estimate a model with only those argument variables, where they turned out impacting.
For those were no argument variable was impacting, we'll only estimate the marginal increase (corresponding to the constant cost of an OPCODE).

```{r}
# `results_df` is assumed to have the columns as the `estimates` data frame has (see below)
add_non_arg_model_estimates <- function(model, results_df, env, opcode) {
  pure_op_count_coeff = summary(model)$coefficients["op_count", 1]
  args_ns = c(NA, NA, NA)
  args_ns_stderr = c(NA, NA, NA)
  results_df[nrow(results_df) + 1, ] = c(opcode, env, FALSE, FALSE, pure_op_count_coeff, args_ns, NA, args_ns_stderr, NA)
  return(results_df)
}
add_arg_model_estimates <- function(model, opcode, env, results_df, df) {
  all_coefficients = summary(model)$coefficients
  arg_coefficients = all_coefficients[!(row.names(all_coefficients) %in% c("op_count", "(Intercept)", "arg0", "arg1", "arg2")),]
  pure_op_count_coeff = all_coefficients["op_count", 1]
  # will be filled if any is impacting
  args_ns = c(NA, NA, NA)
  args_ns_stderr = c(NA, NA, NA)
  
  impact_args = get_impact_args_for(df, opcode, env)
  arg_op_count_names = paste0('op_count:arg', impact_args)

  args_ns[impact_args + 1] = all_coefficients[arg_op_count_names, 'Estimate']
  args_ns_stderr[impact_args + 1] = all_coefficients[arg_op_count_names, 'Std. Error']
  results_df[nrow(results_df) + 1, ] = c(opcode, env, TRUE, TRUE, pure_op_count_coeff, args_ns, NA, args_ns_stderr, NA)
  return(results_df)
}
add_expensive_model_estimates <- function(model, opcode, env, results_df, df) {
  all_coefficients = summary(model)$coefficients
  pure_op_count_coeff = all_coefficients["op_count", 1]
  args_ns = c(NA, NA, NA)
  args_ns_stderr = c(NA, NA, NA)
  expensive =  all_coefficients['op_count:expensiveTRUE', 'Estimate']
  expensive_stderr = all_coefficients['op_count:expensiveTRUE', 'Std. Error']
  results_df[nrow(results_df) + 1, ] = c(opcode, env, TRUE, TRUE, pure_op_count_coeff, args_ns, expensive, args_ns_stderr, expensive_stderr)
  return(results_df)
}
```

```{r}
estimates = data.frame(matrix(ncol = 13, nrow = 0))
colnames(estimates) <- c('opcode', 'env', 'has_significant', 'has_impacting', 'estimate_marginal_ns',
                         'arg0_ns', 'arg1_ns', 'arg2_ns', 'expensive_ns', 'arg0_ns_stderr', 'arg1_ns_stderr', 'arg2_ns_stderr', 'expensive_ns_stderr')

for (env in all_envs) {
  for (opcode in all_opcodes) {
    is_modeled_with_args = nrow(merge(data.frame(opcode=opcode, env=env), models_with_args)) > 0
    is_modeled_with_expensive = nrow(merge(data.frame(opcode=opcode, env=env), models_with_expensive)) > 0
    if (is_modeled_with_expensive) {
      model = arg_lm(measurements, opcode, env, get_expensive_model_formula_for(first_pass, opcode, env))
      estimates = add_expensive_model_estimates(model, opcode, env, estimates, first_pass)
    } else if (is_modeled_with_args) {
      model = arg_lm(measurements, opcode, env, get_model_formula_for(first_pass, opcode, env))
      estimates = add_arg_model_estimates(model, opcode, env, estimates, first_pass)
    } else {
      model = arg_lm(measurements, opcode, env, get_model_formula_for(first_pass, opcode, env))
      estimates = add_non_arg_model_estimates(model, estimates, env, opcode)
    }
    print(c(opcode, env))
    print(summary(model))
  }
}

estimates
```

```{r}
write.csv(estimates, paste0("../../local/argument_estimated_cost", suffix, ".csv"), quote=FALSE, row.names=FALSE)
```

